{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install google-trans-new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI7xkzPxhv0I",
        "outputId": "c573d78f-da2b-479d-decc-20d42e4b5829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-trans-new\n",
            "  Downloading google_trans_new-1.1.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Downloading google_trans_new-1.1.9-py3-none-any.whl (9.2 kB)\n",
            "Installing collected packages: google-trans-new\n",
            "Successfully installed google-trans-new-1.1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi uvicorn pyngrok python-multipart torch torchvision transformers langchain langchain_google_genai streamlit googletrans"
      ],
      "metadata": {
        "id": "O6dGPVQfG4uS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 2kHqCKEBZtYkANyARDYtYfxXGWz_2QSzpWcVfiQE5LH4Akauz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_pVFJF-55XU",
        "outputId": "a718d06e-46aa-4333-bd95-c87295393ec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import numpy as np\n",
        "import cv2\n",
        "import requests\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "font_urls = [\n",
        "    \"https://raw.githubusercontent.com/darrinbright/fonts/main/Fancake.ttf\",\n",
        "    \"https://raw.githubusercontent.com/darrinbright/fonts/main/Milky%20Boba.ttf\",\n",
        "    \"https://raw.githubusercontent.com/darrinbright/fonts/main/gomarice_tofo_steak.ttf\",\n",
        "    \"https://raw.githubusercontent.com/darrinbright/fonts/main/Advertising%20Script%20Bold.ttf\"\n",
        "]\n",
        "\n",
        "font_paths = []\n",
        "for url in font_urls:\n",
        "    response = requests.get(url)\n",
        "    font_name = url.split(\"/\")[-1]\n",
        "    with open(font_name, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "    font_paths.append(font_name)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def generate_poster(prompt):\n",
        "    model_id = \"stabilityai/stable-diffusion-2\"\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(model_id).to(device)\n",
        "    image = pipe(prompt).images[0]\n",
        "    return image\n",
        "\n",
        "def detect_objects(image_pil):\n",
        "    transform = T.Compose([T.ToTensor()])\n",
        "    image_tensor = transform(image_pil).unsqueeze(0).to(device)\n",
        "\n",
        "    model = maskrcnn_resnet50_fpn(pretrained=True).to(device)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictions = model(image_tensor)[0]\n",
        "\n",
        "    boxes = predictions['boxes'].cpu().numpy()\n",
        "    return boxes\n",
        "\n",
        "def add_text_outside_box(image_pil, boxes, catchy_text, font_paths):\n",
        "    resulting_images = []\n",
        "\n",
        "    image = np.array(image_pil)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "    image_height, image_width = image.shape[:2]\n",
        "\n",
        "    if len(boxes) > 0:\n",
        "        x_min, y_min, x_max, y_max = [int(b) for b in boxes[0]]\n",
        "        text_y = (y_min + y_max) // 2\n",
        "\n",
        "        for font_path in font_paths:\n",
        "            try:\n",
        "                font_size = 50\n",
        "                font = ImageFont.truetype(font_path, font_size)\n",
        "            except OSError:\n",
        "                print(f\"Could not load font: {font_path}\")\n",
        "                continue\n",
        "\n",
        "            pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "            draw = ImageDraw.Draw(pil_image)\n",
        "\n",
        "            text_x = x_max + 20\n",
        "\n",
        "            text_bbox = draw.textbbox((text_x, text_y), catchy_text, font=font)\n",
        "            text_width = text_bbox[2] - text_bbox[0]\n",
        "            text_height = text_bbox[3] - text_bbox[1]\n",
        "\n",
        "            if text_x + text_width > image_width:\n",
        "                text_x = image_width - text_width - 20\n",
        "\n",
        "            if text_y + text_height > image_height:\n",
        "                text_y = image_height - text_height - 20\n",
        "\n",
        "            draw.text((text_x, text_y), catchy_text, font=font, fill=(255, 255, 255))\n",
        "\n",
        "            resulting_images.append(pil_image)\n",
        "\n",
        "        return resulting_images\n",
        "    else:\n",
        "        return [image_pil]\n",
        "\n",
        "st.title('Social Spark')\n",
        "\n",
        "product_description = st.text_input('Enter the product description', '')\n",
        "product_type = st.text_input('Enter a prompt for a catchy tagline', '')\n",
        "\n",
        "def generate_catchy_text(tagline_prompt):\n",
        "    prompt_template = f\"\"\"\n",
        "    Generate a short 3-4 words catchy text or slogan for the {product_type} which displays in the advertisement poster.\n",
        "\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "\n",
        "    model = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.4, google_api_key='AIzaSyARn_PcqweM5MXHxYaIWGQcf-BDJMP1bDw')\n",
        "\n",
        "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"product_type\"])\n",
        "\n",
        "    chain = LLMChain(llm=model, prompt=prompt)\n",
        "\n",
        "    catchy_text = chain.run(product_type=product_type)\n",
        "    return catchy_text\n",
        "\n",
        "if st.button('Generate Poster'):\n",
        "    if not product_description or not product_type:\n",
        "        st.error(\"Please provide both a product description and a tagline prompt.\")\n",
        "    else:\n",
        "        poster = generate_poster(prompt=product_description)\n",
        "\n",
        "        boxes = detect_objects(poster)\n",
        "\n",
        "        catchy_text = generate_catchy_text(product_type)\n",
        "\n",
        "        posters_with_text = add_text_outside_box(poster, boxes, catchy_text, font_paths)\n",
        "\n",
        "        if posters_with_text:\n",
        "            for i, img in enumerate(posters_with_text):\n",
        "                img_resized = img.resize((500, 500))\n",
        "                st.image(img_resized, width=500)\n",
        "        else:\n",
        "            st.error(\"No poster generated\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_vN8MjuP3W4",
        "outputId": "9456ab17-1b41-4e1f-b728-e47d1d3065fc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print('Streamlit is accessible at:', public_url)\n",
        "\n",
        "os.system(f\"streamlit run app.py &\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVr0BMJiREnW",
        "outputId": "2f757e08-6d06-4d70-c248-58da9f7f0e2a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit is accessible at: NgrokTunnel: \"https://75e6-34-145-122-128.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DwcGSpGaeb6Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}